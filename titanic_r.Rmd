---
title: 'Práctica 2: Limpieza y análisis de datos '
author: "Autores: Xián Pérez Pérez y Daniel Santos Rivilla"
date: "Junio 2021"
output:
  html_document:
    highlight: default
    number_sections: yes
    theme: cosmo
    toc: yes
    toc_depth: 2
    includes:
      in_header: tipo-header.html
  pdf_document:
    highlight: zenburn
    toc: yes
  word_document: default
---

<style>
   tbody tr:nth-child(odd){
    background-color: #f9f9f9;
  }
</style>


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,  message=FALSE, warning=FALSE)
```


******
# Introducción
******
## Presentación
En esta práctica se elabora un caso práctico orientado a aprender a identificar los datos relevantes para un proyecto analítico y usar las herramientas de integración, limpieza, validación y análisis de las mismas.

## Competencias
En esta práctica se desarrollan las siguientes competencias del Máster de Data Science:

* Capacidad de analizar un problema en el nivel de abstracción adecuado a cada situación y aplicar las habilidades y conocimientos adquiridos para abordarlo y resolverlo.
* Capacidad para aplicar las técnicas específicas de tratamiento de datos (integración, transformación, limpieza y validación) para su posterior análisis. 

## Objetivos
Los objetivos concretos de esta práctica son:

* Aprender a aplicar los conocimientos adquiridos y su capacidad de resolución de problemas en entornos nuevos o poco conocidos dentro de contextos más amplios o multidisciplinares.
* Saber identificar los datos relevantes y los tratamientos necesarios (integración, limpieza y validación) para llevar a cabo un proyecto analítico.
* Aprender a analizar los datos adecuadamente para abordar la información contenida en los datos.
* Identificar la mejor representación de los resultados para aportar conclusiones sobre el problema planteado en el proceso analítico.
* Actuar con los principios éticos y legales relacionados con la manipulación de datos en función del ámbito de aplicación.
* Desarrollar las habilidades de aprendizaje que les permitan continuar estudiando de un modo que tendrá que ser en gran medida autodirigido o autónomo.
* Desarrollar la capacidad de búsqueda, gestión y uso de información y recursos en el ámbito de la ciencia de datos.

## Descripción de la Práctica a realizar
El objetivo de esta actividad será el tratamiento de un dataset, que puede ser el creado en la práctica 1 o bien cualquier dataset libre disponible en Kaggle (https://www.kaggle.com).
Algunos ejemplos de dataset con los que podéis trabajar son:
* Red Wine Quality (https://www.kaggle.com/uciml/red-wine-quality-cortez-et-al-2009)
* Titanic: Machine Learning from Disaster (https://www.kaggle.com/c/titanic)

Siguiendo las principales etapas de un proyecto analítico, las diferentes tareas a realizar (y justificar) son las siguientes:

1. Descripción del dataset. ¿Por qué es importante y qué pregunta/problema pretende responder?
2. Integración y selección de los datos de interés a analizar.
3. Limpieza de los datos.
    1. ¿Los datos contienen ceros o elementos vacíos? ¿Cómo gestionarías cada uno de estos casos?
    2. Identificación y tratamiento de valores extremos.
  
4. Análisis de los datos.
    1. Selección de los grupos de datos que se quieren analizar/comparar (planificación de los análisis a aplicar).
    2. Comprobación de la normalidad y homogeneidad de la varianza.
    3. Aplicación de pruebas estadísticas para comparar los grupos de datos. En función de los datos y el objetivo del estudio, aplicar pruebas de contraste de hipótesis, correlaciones, regresiones, etc. Aplicar al menos tres métodos de análisis diferentes.
  
5. Representación de los resultados a partir de tablas y gráficas.
6. Resolución del problema. A partir de los resultados obtenidos, ¿cuáles son las conclusiones? ¿Los resultados permiten responder al problema?
7. Código: Hay que adjuntar el código, preferiblemente en R, con el que se ha realizado la limpieza, análisis y representación de los datos. Si lo preferís, también podéis trabajar en Python.

## Recursos
Los siguientes recursos son de utilidad para la realización de la práctica:

* Calvo M., Subirats L., Pérez D. (2019). Introducción a la limpieza y análisis de los datos. Editorial UOC.
* Megan Squire (2015). Clean Data. Packt Publishing Ltd.
* Jiawei Han, Micheine Kamber, Jian Pei (2012). Data mining: concepts and techniques. Morgan Kaufmann.
* Jason W. Osborne (2010). Data Cleaning Basics: Best Practices in Dealing with Extreme Scores. Newborn and Infant Nursing Reviews; 10 (1): pp. 1527-3369.
* Peter Dalgaard (2008). Introductory statistics with R. Springer Science & Business Media.
* Wes McKinney (2012). Python for Data Analysis. O’Reilley Media, Inc.
* Tutorial de Github https://guides.github.com/activities/hello-world. 

## Criterios de evaluación
Todos los apartados son obligatorios. La ponderación de los ejercicios es la siguiente:

* Los apartados 1, 2 y 6 valen 0,5 puntos.
* Los apartados 3, 5 y 7 valen 2 puntos.
* El apartado 4 vale 2,5 puntos.

Se valorará la idoneidad de las respuestas, que deberán ser claras y completas. Las diferentes etapas deberán justificarse y acompañarse del código correspondiente. También se valorará la síntesis y claridad, a través del uso de comentarios, del código resultante, así como la calidad de los datos finales analizados.

## Formato y fecha de entrega
En referente a la entrega final, hay que entregar un único fichero que contenga el enlace Github, el cual no se podrá modificar posteriormente a la fecha de entrega, donde haya:

1. Una Wiki con los nombres de los componentes del grupo y una descripción de los ficheros.
2. Un documento PDF con las respuestas a las preguntas y los nombres de los componentes del grupo. Además, al final del documento, deberá aparecer la siguiente tabla de contribuciones al trabajo, la cual debe firmar cada integrante del grupo con sus iniciales.
3. Una carpeta con el código generado para analizar los datos.
4. El fichero CSV con los datos originales.
5. El fichero CSV con los datos finales analizados.

Este documento de entrega final de la Práctica 2 se debe entregar en el espacio de Entrega y Registro de AC del aula antes de las 23:59 del día 8 de junio. No se aceptarán entregas fuera de plazo.


******
# Desarrollo de la práctica  
******

## Introducción.

Para el desarrollo de la práctica 2 de **Tipología y ciclo de vida de los datos** se ha seleccionado el dataset de Titanic expuesto en kaggle. Este dataset consta de dos ficheros .csv (test y train) en los que se encuentra recogida la información a cerca de los pasajeros del célebre crucero. Esta separación inicial está fundamentada por su objetivo de aplicar un modelo de predicción para determinar los supervivientes del accidente, de modo que uno de los conjuntos se emplee para el entrenamiento del modelo y el otro para ponerlo a prueba. Para nuestro estudio emplearemos el conjunto de entrenamiento **train** puesto que es el que cuenta con la información relativa a la supervivencia de los pasajeros.

## Carga de datos.

Se procede a llevar a cabo la carga de datos de **train.csv** y almacenarlos en forma de dataframe.

```{r Imports}
# Cargamos los paquetes R que vamos a usar
library(ggplot2)
library(dplyr)
library(gridExtra)
library(ggcorrplot)
#library(GGally)
```


```{r}
# Cargamos el fichero de datos
train <- read.csv('train.csv', stringsAsFactors = FALSE)
# Verificamos la estructura del conjunto de datos
str(train)
```

## Descripción del dataset.

En este apartado se tratará de llevar a cabo una descripción detallada del conjunto de datos, con lo que se definirán los atributos del mismo, las proporciones y posibles valores de los mismos e información relevante para procesos posteriores. En primer lugar, los atributos del conjunto de datos:

* Name: un atributo de tipo texto con el nombre del pasajero.
* Sex: un atributo de tipo texto que especifica el género del pasajero. Puede tomar los valores: _male_, _female_.
* Age: atributo numérico que determina la edad del pasajero. La edad de los bebés por debajo de 12 meses se representa como una fracción del tipo 1/_meses de vida_.En caso de tratarse de una edad estimada se representa con la forma _xx.5_.
* Pclass: un atributo de tipo numérico que representa la clase a la que pertenece el pasajero. Existen las clases: _1_, _2_ y _3_ que coinciden con clase alta, clase media y clase baja respectivamente.
* Embarked: atributo de tipo texto que determina la pasarela de embarque del pasajero.Toma los valores: _S_ (Southampton), _C_ (Cherbourg) y _Q_ (Queenstown).
* Ticket: atributo de tipo texto con el código del billete del pasajero.
* Fare: atributo numérico con el precio que ha pagado el pasajero. Entendemos aquellos valores de 0, como que el pasajero en cuestión es un empleado en la nave.
* Sibsp: atributo numérico que especifica la cantidad de hermanos y/o cónyuges a bordo del barco.
* Prch:  atributo numérico que especifica la cantidad de padres y/o hijos a bordo del barco.
* Survived: atributo booleano que especifica si el pasajero ha sobrevivido al accidente o no. Se entiende _0_ como defunción y _1_ como supervivencia.
* Cabin: atributo de tipo texto que especifica el camarote en el que reside el pasajero.

Una vez definidos los atributos del conjunto, se procede a estudiar superficialmente los datos de modo que se puedan detectar ciertas tendencias o naturalezas.

```{r}
# Comprobamos los distintos valores de los atributos que parecen ser categóricos
unique(train$Survived)
unique(train$Pclass)
unique(train$Sex)
unique(train$Embarked)
```

```{r}
#Estadísticas básicas
summary(train)
```

Tras la ejecución de un *summary* se puede observar la naturaleza de los datos y parte de su distribución. Aunque este tipo de resumen puede resultar de gran utilidad, es necesario tener en cuenta que en ciertos casos puede llevar a equívocos puesto que se podría obviar el significado de ciertos atributos, fundamentalmente en aquellos categóricos de tipo numérico.En cambio, en el caso de atributos no categóricos de tipo numérico se puede extraer información de mayor interés. 
En este caso se observa que el precio de los billetes es 32.2 de media y se aprecia que el valor máximo se aleja mucho de éste, por lo que podría ser un valor erroneo.
En cuanto al número de familias viajando en la nave se podría decir que conforman una minoría y que lo más común son viajeros individuales o con un único familiar o pareja.
La distribución de edad es relativamente baja por lo que se puede suponer que la mayoría de pasajeros son jóvenes (por debajo de 40 años).

```{r}
#Previsualizacion de datos
head(train)
tail(train)
```

En ciertas ocasiones, la previsualización de los datos tal y como se han cargado puede ayudar a la identificación de ciertos detalles de los distintos atributos, tanto en cuanto a su significado como en cuanto a los valores que pueden tomar. En este caso se puede observar que los tipos de datos y sus valores coinciden con la definición de los atributos aunque salen a la luz otro factores como:

* Existencia de valores no numéricos para el atributo *Age*.
* Valores vacíos en el atributo no numérico *Cabin*

Aunque este método aporta cierta luz sobre los datos, no es suficiente, y por ello se deben llevar a cabo otras tareas para la correcta comprensión del conjunto de datos.

```{r}
# Estadísticas de valores vacíos
colSums(is.na(train))
colSums(train=="")
```

Aparentemente, en el conjunto existe una alta cantidad de valores inválidos para el atributo *Age*, teniendo en cuenta que el conjunto cuenta con 891 registros. En cuanto a las cabinas se puede suponer que no todos los pasajeros contaban con una propia y por ello ese campo aparece vacío ya que la mayoría de pasajeros se encuentran con esta carencia. Sin embargo, en cuanto al atributo *Embarked* si que podemos concluir en que existen 2 registros que no fueron tomados y por lo tanto el conjunto de datos carece de dicha información.

## Preparación del dataset.

Tras las observaciones llevadas a cabo en el apartado anterior se realizarán ciertas tareas y acciones sobre el conjunto de datos en vistas a facilitar y mejorar los resultados del futuro análisis.

### Tratamiento de valores nulos o vacíos.

En cuanto a los valores no numéricos encontrados para el atributo *Age*, dado que su eliminación sería una pérdida significativa para los análisis posteriores, se lleva a cabo la sustitucion de estos valores inválidos por el valor medio del atributo.

```{r}
# Tomamos la media para valores vacíos de la variable "Age"
train$Age[is.na(train$Age)] <- mean(train$Age,na.rm=T)
```

Tratándose del atributo *Embarked*, como se ha mostrado anteriormente solo existen 2 registros vacíos con lo que se puede eliminar perfectamente la información de estos pasajeros.

```{r}
# Se eliminan las filas co
train <- train[train$Embarked!="",]
```

En cuanto al atributo *Cabin* dada la suposición antes mencionada se considera que es un valor válido que implica la carencia de un camarote por lo que se procede a asignar un valor más representativo como podría ser "Sin camarote".

```{r}
# Asignamos un valor significativo a los registros sin camarote
train$Cabin[train$Cabin == ""] <- "Sin camarote"
```

### Discretización de variables.

Para el caso del atributo de edad será mas interesante tratarlo como si fuese una categoría por lo que se lleva a cabo una discretización que resultará en la existencia de 8 rangos de edad.

```{r}
# Se discretiza Age
train$Age <- cut(train$Age, breaks = c(0, 10, 20, 30, 40, 50, 60, 70, 100), labels = c("0-9", "10-19", "20-29", "30-39", "40-49", "50-59", "60-69", "70-80"))
# Se previsualizan los datos
head(train)
```

### Factorización de variables
Cambiamos el tipo de los atributos que lo necesitan a factor

```{r}
# Transformación
train$Survived <- as.factor(train$Survived)
train$Pclass <- as.factor(train$Pclass)
train$Sex <- as.factor(train$Sex)
train$Embarked <- as.factor(train$Embarked)
```



## Análisis de los datos.

Nos proponemos analizar las relaciones entre las diferentes variables del conjunto de datos para ver si se relacionan y como. Empezamos con las variables categóricas y su relación con Survived

```{r, fig.width=10}
# Visualizamos la relación entre las variables:
g1 <- ggplot(data=train, aes(x=Pclass, fill = Survived)) +
  geom_bar(position = "stack") +
  theme_minimal()

g2 <- ggplot(data=train, aes(x=Sex, fill = Survived)) +
  geom_bar(position = "stack") +
  theme_minimal()


g3 <- ggplot(data=train, aes(x=Age, fill = Survived)) +
  geom_bar(position = "stack") +
  theme_minimal()

g4 <- ggplot(data=train, aes(x=Embarked, fill = Survived)) +
  geom_bar(position = "stack") +
  theme_minimal()

grid.arrange(g1, g2, g3, g4, nrow = 2, ncol = 2)

```


```{r, fig.width=10}
# Visualizamos la relación entre las variables:
g1 <- ggplot(data=train, aes(x=Pclass, fill = Survived)) +
  geom_bar(position = "fill") +
  theme_minimal()

g2 <- ggplot(data=train, aes(x=Sex, fill = Survived)) +
  geom_bar(position = "fill") +
  theme_minimal()


g3 <- ggplot(data=train, aes(x=Age, fill = Survived)) +
  geom_bar(position = "fill") +
  theme_minimal()

g4 <- ggplot(data=train, aes(x=Embarked, fill = Survived)) +
  geom_bar(position = "fill") +
  theme_minimal()

grid.arrange(g1, g2, g3, g4, nrow = 2, ncol = 2)

```


```{r}
ggplot(data=train, aes(x=Pclass, y=Sex)) +
  geom_jitter() +
  theme_minimal()
```


```{r}
library(GGally)
 
# From the help page:
data(tips, package = "reshape")
ggpairs(
  tips[, c(1, 3, 4, 2)],
  upper = list(continuous = "density", combo = "box_no_facet"),
  lower = list(continuous = "points", combo = "dot_no_facet")
)
```




```{r, fig.width=10}
train_cat <- train[, c("Pclass", "Sex", "Age", "Embarked")]
model.matrix(~0+., data=train_cat) %>% 
  cor(use="pairwise.complete.obs") %>% 
  ggcorrplot(show.diag = F, type="lower", lab=TRUE, lab_size=2)
```

```{r}


```



En la primera gráfica podemos observar fácilmente la cantidad de mujeres que viajaban respecto hombres y observar los que no sobrevivieron. Numéricamente el número de hombres y mujeres supervivientes es similar.

En la segunda gráfica de forma porcentual observamos los puertos de embarque y los porcentajes de supervivencia en función del puerto. Se podría trabajar el puerto C (Cherburgo) para ver de explicar la diferencia en los datos. Quizás porcentualmente embarcaron más mujeres o niños... O gente de primera clase?

Obtenemos ahora una matriz de porcentajes de frecuencia.
Vemos, por ejemplo que la probabilidad de sobrevivir si se embarcó en "C" es de un 56.45%

```{r}
t<-table(totalData[1:filas,]$embarked,totalData[1:filas,]$survived)
for (i in 1:dim(t)[1]){
    t[i,]<-t[i,]/sum(t[i,])*100
}
t
```

Veamos ahora como en un mismo gráfico de frecuencias podemos trabajar con 3 variables: Embarked, Survived y Pclass.  

```{r}
# Ahora, podemos dividir el gráfico de Embarked por Pclass:
ggplot(data = totalData[1:filas,],aes(x=embarked,fill=survived))+geom_bar(position="fill")+facet_wrap(~class)
```

Aquí ya podemos extraer mucha información. Como propuesta de mejora se podría hacer un gráfico similar trabajando solo la clase. Habría que unificar toda la tripulación a una única categoría.

Comparemos ahora dos gráficos de frecuencias: Survived-SibSp y Survived-Parch

```{r}
# Survivial como función de SibSp y Parch
ggplot(data = totalData[1:filas,],aes(x=sibsp,fill=survived))+geom_bar()
ggplot(data = totalData[1:filas,],aes(x=parch,fill=survived))+geom_bar()
# Vemos como las forma de estos dos gráficos es similar. Este hecho nos puede indicar presencia de correlaciones altas.
```

Veamos un ejemplo de construcción de una variable nueva: Tamaño de familia

```{r}

# Construimos un atributo nuevo: family size.
totalData$FamilySize <- totalData$sibsp + totalData$parch +1;
totalData1<-totalData[1:filas,]
ggplot(data = totalData1[!is.na(totalData[1:filas,]$FamilySize),],aes(x=FamilySize,fill=survived))+geom_histogram(binwidth =1,position="fill")+ylab("Frecuencia")

  
```

Veamos ahora dos gráficos que nos compara los atributos Age y Survived.  
Observamos como el parámetro position="fill" nos da la proporción acumulada de un atributo dentro de otro

```{r}
# Survival como función de age:
ggplot(data = totalData1[!(is.na(totalData[1:filas,]$age)),],aes(x=age,fill=survived))+geom_histogram(binwidth =3)
ggplot(data = totalData1[!is.na(totalData[1:filas,]$age),],aes(x=age,fill=survived))+geom_histogram(binwidth = 3,position="fill")+ylab("Frecuencia")
```

## Conclusiones.

